{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell-collective-control-kernels.ipynb\n",
    "#\n",
    "# Bryan Daniels\n",
    "# 2023/11/2\n",
    "#\n",
    "# Computing control kernels for relevant networks in the cell collective database.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0456963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neet.boolean import LogicNetwork\n",
    "from neet.controlkernel.control_kernel_analysis import ck_analysis\n",
    "from neet.controlkernel.modularity import pinning_produces_desired_attractor\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c9912",
   "metadata": {},
   "source": [
    "# Load networks from Cell Collective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2b9df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cell_collective_network(directory):\n",
    "    \"\"\"\n",
    "    Creates neet network from cell collective data in the given directory.\n",
    "    \"\"\"\n",
    "    expressions_file = '{}/expressions.txt'.format(directory)\n",
    "    external_file = '{}/external.txt'.format(directory)\n",
    "    net = LogicNetwork.read_logic(expressions_file, external_file)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1109a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_collective_directory = '../Data/Cell Collective/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d390048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 72/72 [00:07<00:00,  9.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# load all cell collective networks into a dictionary\n",
    "net_dict = {}\n",
    "skip_network = 'ErbB_Receptor_Signaling' # skip this network because it is too large\n",
    "for network_directory in tqdm(glob.glob(cell_collective_directory+\"/*\")):\n",
    "    if os.path.isdir(network_directory) and not network_directory.endswith(skip_network):\n",
    "        #print(\"Loading network from directory {}\".format(network_directory))\n",
    "        net_name = os.path.split(network_directory)[-1]\n",
    "        net = load_cell_collective_network(network_directory)\n",
    "        #print(\"net_name = {}\".format(net_name))\n",
    "        net_dict[net_name] = net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad11e1c-66ec-4f75-9295-09461e9610f2",
   "metadata": {},
   "source": [
    "# Find attractors for networks with 2 attractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ba41b9-ca2c-471d-b8c5-08b42db10f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 0, 0, 0]]\n",
      "[[0, 0, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "net = net_dict['Cortical_Area_Development']\n",
    "for a in net.attractors:\n",
    "    print([ net.decode(state) for state in a ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b890989-55db-4e3e-9159-efe18652ef24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0] -> [1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0] -> [1, 1, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0] -> [1, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0] -> [1, 1, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0] -> [0, 0, 0, 1, 0]\n",
      "[1, 0, 1, 0, 0] -> [0, 0, 0, 1, 0]\n",
      "[0, 1, 1, 0, 0] -> [0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 0, 0] -> [0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0] -> [0, 0, 0, 0, 1]\n",
      "[1, 0, 0, 1, 0] -> [0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 1, 0] -> [0, 0, 0, 0, 0]\n",
      "[1, 1, 0, 1, 0] -> [0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 1, 0] -> [0, 0, 1, 1, 1]\n",
      "[1, 0, 1, 1, 0] -> [0, 0, 1, 1, 0]\n",
      "[0, 1, 1, 1, 0] -> [0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 0] -> [0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1] -> [1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 1] -> [1, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 1] -> [1, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 1] -> [1, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 1] -> [0, 0, 0, 1, 0]\n",
      "[1, 0, 1, 0, 1] -> [0, 0, 0, 1, 0]\n",
      "[0, 1, 1, 0, 1] -> [0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 0, 1] -> [0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 1] -> [0, 0, 0, 0, 1]\n",
      "[1, 0, 0, 1, 1] -> [0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 1, 1] -> [0, 0, 0, 0, 0]\n",
      "[1, 1, 0, 1, 1] -> [0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 1, 1] -> [0, 0, 1, 1, 1]\n",
      "[1, 0, 1, 1, 1] -> [0, 0, 1, 1, 0]\n",
      "[0, 1, 1, 1, 1] -> [0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1, 1] -> [0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# also print transition graph\n",
    "for i,end_state in enumerate(net.transitions):\n",
    "    print(net.decode(i),'->',net.decode(end_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b107cfb2-b1e8-46da-97f7-c629d4712cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "[[1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1]]\n",
      "[[0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "net = net_dict['Human_Gonadal_Sex_Determination']\n",
    "for a in net.attractors:\n",
    "    print([ net.decode(state) for state in a ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbf58bbc-4547-4c1d-9a52-3c87526165f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FGF9',\n",
       " 'SRY',\n",
       " 'RSPO1',\n",
       " 'UGR',\n",
       " 'WT1pKTS',\n",
       " 'SOX9',\n",
       " 'GATA4',\n",
       " 'PGD2',\n",
       " 'DMRT1',\n",
       " 'FOXL2',\n",
       " 'CBX2',\n",
       " 'WNT4',\n",
       " 'WT1mKTS',\n",
       " 'DKK1',\n",
       " 'AMH',\n",
       " 'CTNNB1',\n",
       " 'NR0B1',\n",
       " 'DHH',\n",
       " 'NR5A1']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52afc3",
   "metadata": {},
   "source": [
    "# Do example control kernel analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520be1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# control kernel analysis on an example network\n",
    "net = net_dict['Cortical_Area_Development']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "88bbb609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# force first gene on explicitly\n",
    "#net2 = load_cell_collective_network('../Data/Cell Collective/Cortical_Area_Development_forced_231102')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d199adb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding attractors and control kernels...\n",
      "Control kernel for attractor [[1 1 0 0 0]]:\n",
      "    ['Emx2']\n",
      "Control kernel for attractor [[0 0 1 1 1]]:\n",
      "    ['Fgf8']\n"
     ]
    }
   ],
   "source": [
    "# the default code finds a single control kernel (of minimal size) for each attractor\n",
    "ck_data = ck_analysis(net)\n",
    "attractor_list = ck_data['attractors']\n",
    "ck_list = ck_data['control_kernels']\n",
    "for att,ck in zip(attractor_list,ck_list):\n",
    "    ck_names = [ net.names[i] for i in ck ]\n",
    "    print('Control kernel for attractor {}:'.format(np.transpose(net.decode(att))))\n",
    "    print('    {}'.format(ck_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c73dd2a-b1b9-4fa9-bea5-7188ee16b8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 1, 0, 0, 0]], [[0, 0, 1, 1, 1]]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[ net.decode(state) for state in att ] for att in net.attractors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cc8cbfa-b8b6-4ee3-98af-585f5fddb97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28,  4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.basin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "faa7d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for finding all possible control kernels of size 1 \n",
    "# (copied from Control-of-Synthetic-Boolean-Networks/code/BoolODE_data.ipynb)\n",
    "def find_all_control_kernels_of_size_one(net):\n",
    "    attractors = net.attractors\n",
    "    for att_index in range(len(attractors)):\n",
    "        desired_attractor = attractors[att_index].copy()\n",
    "        desired_attractor_decoded = [net.decode(state) for state in desired_attractor]\n",
    "        print(\"Control kernels of size one for attractor {}\".format(desired_attractor_decoded))\n",
    "        for i,name in enumerate(net.names):\n",
    "            pin = [i,]\n",
    "            pin_states = [[desired_attractor_decoded[0][i],],]\n",
    "            if pinning_produces_desired_attractor(net,pin,pin_states,desired_attractor):\n",
    "                print({name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91896dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g1 <-> Coup_fti\n",
      "g2 <-> Emx2\n",
      "g3 <-> Fgf8\n",
      "g4 <-> Sp8\n",
      "g5 <-> Pax6\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"g{} <-> {}\".format(i+1,net.names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "746bb1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control kernels of size one for attractor [[1, 1, 0, 0, 0]]\n",
      "{'Emx2'}\n",
      "{'Fgf8'}\n",
      "{'Sp8'}\n",
      "Control kernels of size one for attractor [[0, 0, 1, 1, 1]]\n",
      "{'Fgf8'}\n"
     ]
    }
   ],
   "source": [
    "find_all_control_kernels_of_size_one(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ac7c4a",
   "metadata": {},
   "source": [
    "### What are the Cortical Area Network's dynamics from some example initial conditions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96147f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_to_attractor(net,state):\n",
    "    traj = []\n",
    "    while state not in traj:\n",
    "        traj.append(state.copy())\n",
    "        state = net.update(traj[-1].copy())\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "84a949e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 0]\n",
      "[0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# starting from the initial conditions in AY's \"pRogress_4\"\n",
    "[ print(state) for state in simulate_to_attractor(net,[0,0,1,1,0]) ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c3490f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[1, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "[ print(state) for state in simulate_to_attractor(net,[0,0,0,1,0]) ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e6da190c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "[ print(state) for state in simulate_to_attractor(net,[0,0,0,0,0]) ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "32687f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 0]\n",
      "[0, 0, 1, 1, 0]\n",
      "[0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "[ print(state) for state in simulate_to_attractor(net,[1,0,1,1,0]) ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2fc2be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
